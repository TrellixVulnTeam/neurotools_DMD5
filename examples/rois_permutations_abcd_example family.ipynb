{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "changing-hurricane",
   "metadata": {},
   "source": [
    "# Permutation Test with nested family\n",
    "\n",
    "For this example problem, we will just use a set of thickness ROI's, just family id as the block structure, and a single confounding variable of sex, and let's say neurocog1 as our target variable. Our dataset we are using is from the ABCD study.\n",
    "\n",
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "stylish-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from neurotools.stats.permutations import permuted_v\n",
    "from neurotools.loading.abcd import load_from_csv, load_family_block_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "naughty-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get possible columns\n",
    "csv_loc = '/home/sage/benchmark_methods/data/nda3.0.csv'\n",
    "all_cols = list(pd.read_csv(csv_loc, nrows=0))\n",
    "\n",
    "# Load thickness ROI data - ignore hemi and full mean for plotting\n",
    "thick = [col for col in all_cols if 'smri_thick_cort.destrieux' in col and '_mean' not in col]\n",
    "\n",
    "# Rest of needed columns\n",
    "rest = ['C(sex_at_birth)', 'neurocog_pc1.bl', 'C(rel_family_id)']\n",
    "\n",
    "# Load in all together\n",
    "data = load_from_csv(cols=thick+rest, csv_loc=csv_loc, drop_nan=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-driver",
   "metadata": {},
   "source": [
    "### Run the permutation test\n",
    "\n",
    "So how should be use the rel_family_id variable with information on the unique family of each subject? One option would be to use the values directly to define groups and the families themselves, where if we set parameter within_grp to True, this would mean that swaps will only be performed within group, so in terms of family, that means the only swaps that would take place are within families, swapping siblings data with each other. What that also means is that we would not be allowing any swaps to take place between say two random subjects with no other family members (this likely is not what we want from a null model).\n",
    "\n",
    "On the other hand, we could use the family information to define block-wise swap. That is to say, so every singleton family is freely swapped with other singleton families, but any family of size 2, can only be swapped with another family of size 2. In this case though, what happens internally further is that the data is split into different variance groups. The set of all single-tons for example all fall under the same unique variance group, then for the set of families of size two, we compute two new variance groups, reflecting the subjects data which are allowed to swap. So for example:\n",
    "\n",
    "- sub1 - family 1\n",
    "- sub2 - family 2 \n",
    "- sub3 - family 2 \n",
    "- sub4 - family 3 \n",
    "- sub5 - family 3 \n",
    "\n",
    "The only possible swap here is subj2 and subj3's values with subj4 and subj5 as a block-level swap. So the different automatically computed variance groups would be:\n",
    "\n",
    "- sub1 - family 1 - vg = 1\n",
    "- sub2 - family 2 - vg = 2\n",
    "- sub3 - family 2 - vg = 3\n",
    "- sub4 - family 3 - vg = 2\n",
    "- sub5 - family 3 - vg = 3\n",
    "\n",
    "Since sub2 and sub4 can swap, and sub3 and sub5 can swap, so they have the same variance group. This is imporant because in calculating the v-score, stats are computed for each variance group seperately, then summed. But are these the swaps and variance groups we want? It seems more desirable actually that we would allow another level of swaps to occur, that is to say, members of the same family should be allowed to swap too, right? Likewise, there is no real reason the first member of family 2 should be in a seperate variance group from the second member of family 2, instead we likely want them all to be in the same variance group. So something like this:\n",
    "\n",
    "- sub1 - family 1 - vg = 1\n",
    "\n",
    "- sub2 - family 2 - vg = 2\n",
    "- sub3 - family 2 - vg = 2\n",
    "\n",
    "- sub4 - family 3 - vg = 2\n",
    "- sub5 - family 3 - vg = 2\n",
    "\n",
    "Where now what we are explicitly concerned with is not the unique family, but the size of the family.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "scheduled-dominican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 5.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, cnts = np.unique(data['rel_family_id'], return_counts=True)\n",
    "data['family_size'] = data['rel_family_id'].replace(dict(zip(unique, cnts)))\n",
    "np.unique(data['family_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "taken-saint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_size</th>\n",
       "      <th>neg_rel_family_id</th>\n",
       "      <th>ones</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDAR_INV003RTV85</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-6763.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV005V6D2C</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-7934.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV007W6H7B</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3691.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV00BD7VDC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2923.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV00CY2MDM</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-4180.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INVZZL0VA2F</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-7707.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INVZZLZCKAY</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-7246.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INVZZPKBDAC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1960.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INVZZZ2ALR6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-5442.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INVZZZNB0XC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-5150.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10899 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  family_size  neg_rel_family_id  ones\n",
       "src_subject_id                                        \n",
       "NDAR_INV003RTV85          1.0            -6763.0     1\n",
       "NDAR_INV005V6D2C          1.0            -7934.0     1\n",
       "NDAR_INV007W6H7B          1.0            -3691.0     1\n",
       "NDAR_INV00BD7VDC          1.0            -2923.0     1\n",
       "NDAR_INV00CY2MDM          2.0            -4180.0     1\n",
       "...                       ...                ...   ...\n",
       "NDAR_INVZZL0VA2F          2.0            -7707.0     1\n",
       "NDAR_INVZZLZCKAY          1.0            -7246.0     1\n",
       "NDAR_INVZZPKBDAC          1.0            -1960.0     1\n",
       "NDAR_INVZZZ2ALR6          1.0            -5442.0     1\n",
       "NDAR_INVZZZNB0XC          1.0            -5150.0     1\n",
       "\n",
       "[10899 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['neg_rel_family_id'] = -data['rel_family_id']\n",
    "data['ones'] = 1\n",
    "\n",
    "permutation_structure = data[['family_size', 'neg_rel_family_id', 'ones']]\n",
    "permutation_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-arrow",
   "metadata": {},
   "source": [
    "So with this family size variable, an easy way to set this up is now within_grp=True. Where we allow swaps just within each of the unique groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deluxe-bahamas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:   17.1s finished\n"
     ]
    }
   ],
   "source": [
    "pvals, original_scores, h0_vmax = permuted_v(tested_vars=data['neurocog_pc1.bl'],\n",
    "                                             target_vars=data[thick],\n",
    "                                             confounding_vars=data['sex_at_birth'],\n",
    "                                             permutation_structure=permutation_structure,\n",
    "                                             within_grp=True,\n",
    "                                             n_perm=1,\n",
    "                                             n_jobs=4,\n",
    "                                             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-azerbaijan",
   "metadata": {},
   "source": [
    "### Make some plots of our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurotools.plotting import SurfRef, plot\n",
    "\n",
    "def to_vertex(vals, names, space='fsaverage'):\n",
    "    '''Helper function to convert destr. ROIs to vertex space'''\n",
    "    \n",
    "    plot_df = pd.DataFrame(vals, columns=['vals'])\n",
    "    plot_df['names'] = names\n",
    "\n",
    "    surf_ref = SurfRef(space=space, parc='destr')\n",
    "    plot_data = surf_ref.get_hemis_plot_vals(plot_df, lh_key='.lh', rh_key='.rh')\n",
    "    \n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_names = list(data[thick])\n",
    "v = to_vertex(original_scores, roi_names)\n",
    "plot(v, title='Raw v-stats', threshold=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_log_pvals = -np.log10(pvals)\n",
    "v = to_vertex(neg_log_pvals , roi_names)\n",
    "plot(v, title='Neg log10 pvals', threshold=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_scores = original_scores.copy()\n",
    "thresh_scores[pvals > .05] = 0\n",
    "\n",
    "v = to_vertex(thresh_scores, roi_names)\n",
    "plot(v, title='Thresholded V stats', threshold=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-remains",
   "metadata": {},
   "source": [
    "What about for ML / Multi-variate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "lyric-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurotools.random.permute_blocks import block_permutation\n",
    "import BPt as bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pregnant-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bp.Dataset(data)\n",
    "data = data.set_role('neurocog', 'target')\n",
    "data = data.set_role(['sex_at_birth', 'family_size', 'neg_rel_family_id', 'ones', 'rel_family_id'], 'non input')\n",
    "\n",
    "subjs = data.index[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "consistent-interpretation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting target = neurocog_pc1.bl\n",
      "Using problem_type = regression\n",
      "Using scope = all (defining a total of 148 features).\n",
      "Evaluating 500 total data points.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfe4e4b5fa4498fbd42888f1130f250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set: (400, 148)\n",
      "Validation Set: (100, 148)\n",
      "Fit fold in 1.8 seconds.\n",
      "explained_variance: 0.0829\n",
      "neg_mean_squared_error: -0.6376\n",
      "\n",
      "Training Set: (400, 148)\n",
      "Validation Set: (100, 148)\n",
      "Fit fold in 2.1 seconds.\n",
      "explained_variance: 0.0343\n",
      "neg_mean_squared_error: -0.4570\n",
      "\n",
      "Training Set: (400, 148)\n",
      "Validation Set: (100, 148)\n",
      "Fit fold in 1.9 seconds.\n",
      "explained_variance: 0.1044\n",
      "neg_mean_squared_error: -0.4624\n",
      "\n",
      "Training Set: (400, 148)\n",
      "Validation Set: (100, 148)\n",
      "Fit fold in 2.2 seconds.\n",
      "explained_variance: 0.0585\n",
      "neg_mean_squared_error: -0.6158\n",
      "\n",
      "Training Set: (400, 148)\n",
      "Validation Set: (100, 148)\n",
      "Fit fold in 3.6 seconds.\n",
      "explained_variance: 0.0839\n",
      "neg_mean_squared_error: -0.5940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = bp.evaluate('ridge_pipe', data, subjects=subjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "continent-rebound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0728174110395607"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score = results.score\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "organizational-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_perm = 10\n",
    "p_scores = []\n",
    "for repeat in range(n_perm):\n",
    "    \n",
    "    p_data = data.copy()\n",
    "\n",
    "    # Permute the subjects randomly\n",
    "    permuted_subjs = np.random.permutation(subjs)\n",
    "    \n",
    "    # Or permute according to restrictions\n",
    "    permuted_subjs = block_permutation(subjs, blocks=permutation_structure.loc[subjs],\n",
    "                                       within_grp=True)\n",
    "\n",
    "    # Apply permutation to the target\n",
    "    p_data.loc[subjs, 'neurocog_pc1.bl'] = np.array(p_data.loc[permuted_subjs, 'neurocog_pc1.bl'])\n",
    "\n",
    "    p_results = bp.evaluate('ridge_pipe', p_data, subjects=subjs,\n",
    "                            eval_verbose=-1, progress_bar=None)\n",
    "    p_scores.append(p_results.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-utility",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('bpt': conda)",
   "language": "python",
   "name": "python391jvsc74a57bd0816e2859f723fb77ad3214da0fbda681e8d4db93bd8b118618b521c0b1f5f48f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
